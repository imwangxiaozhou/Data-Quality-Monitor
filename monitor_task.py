import datetime
import csv
import os
import re
from hive_checker import HiveChecker
from wechat_sender import WeChatSender

# é…ç½®ä¿¡æ¯
HIVE_HOST = '192.168.10.3'
HIVE_PORT = 10000
HIVE_USER = 'hadoop'

# ç›®æ ‡è¡¨åˆ—è¡¨
TARGET_TABLES = [
    "glsx_data_warehouse.ads_black_abnormal_area_zl_res",
    "glsx_data_warehouse.ads_zlgj_24hour_offline_black_area_res",
    "glsx_data_warehouse.ads_zlgj_24hour_stay_black_area_res",
    "glsx_data_warehouse.ads_zlgj_48hour_offline_black_area_res",
    "glsx_data_warehouse.ads_zlgj_48hour_stay_black_area_res",
    "glsx_data_warehouse.ads_zlgj_offline_warning_black_area_res",
    "glsx_data_warehouse.ads_zlgj_stay_warning_black_area_res"
]

# ä¼ä¸šå¾®ä¿¡ Webhook
WEBHOOK_URL = "https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=d741ee77-b177-4f92-b478-e5357cadf990"

def get_date_str(days_offset=0):
    """è·å–æŒ‡å®šåç§»é‡çš„æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)"""
    return (datetime.datetime.now() - datetime.timedelta(days=days_offset)).strftime('%Y-%m-%d')

def clean_old_reports(days=30):
    """æ¸…ç†æŒ‡å®šå¤©æ•°ä¹‹å‰çš„æŠ¥å‘Šæ–‡ä»¶"""
    report_dir = os.path.join(os.getcwd(), "reports")
    if not os.path.exists(report_dir):
        return
        
    print(f"å¼€å§‹æ¸…ç† {days} å¤©å‰çš„æŠ¥å‘Šæ–‡ä»¶...")
    threshold_date = datetime.datetime.now() - datetime.timedelta(days=days)
    
    for filename in os.listdir(report_dir):
        # åŒ¹é… detail_report_YYYY-MM-DD.csv
        match = re.search(r'detail_report_(\d{4}-\d{2}-\d{2})\.csv', filename)
        if match:
            file_date_str = match.group(1)
            try:
                file_date = datetime.datetime.strptime(file_date_str, '%Y-%m-%d')
                if file_date < threshold_date:
                    file_path = os.path.join(report_dir, filename)
                    os.remove(file_path)
                    print(f"å·²åˆ é™¤è¿‡æœŸæŠ¥å‘Š: {filename}")
            except ValueError:
                continue

def check_table_status_detail(max_ds, count):
    """
    æ£€æŸ¥è¡¨çŠ¶æ€ (è¿”å›è¯¦ç»†æ£€æŸ¥é¡¹)
    :param max_ds: æœ€å¤§åˆ†åŒºæ—¥æœŸ
    :param count: æ•°æ®é‡
    :return: æ£€æŸ¥é¡¹åˆ—è¡¨
    """
    today = get_date_str(0)
    yesterday = get_date_str(1)
    
    checks = []
    
    # 1. æ•°æ®æ—¶æ•ˆæ£€æŸ¥
    is_date_valid = max_ds in [today, yesterday]
    date_msg = f"{max_ds}" if max_ds else "NULL"
    if not is_date_valid:
        date_msg += " (æ»å)"
    checks.append({
        "name": "æ•°æ®æ—¶æ•ˆ",
        "passed": is_date_valid,
        "msg": date_msg
    })
    
    # 2. æ•°æ®é‡æ£€æŸ¥
    is_count_valid = count > 0
    count_msg = f"{count}æ¡"
    if not is_count_valid:
        count_msg += " (å¼‚å¸¸)"
    checks.append({
        "name": "æ•°æ®é‡",
        "passed": is_count_valid,
        "msg": count_msg
    })
    
    return checks

def save_details_to_csv(all_data, filename):
    """ä¿å­˜æ˜ç»†æ•°æ®åˆ° CSV æ–‡ä»¶"""
    if not all_data:
        print("æ²¡æœ‰æ˜ç»†æ•°æ®éœ€è¦ä¿å­˜")
        return None
        
    # æå–æ‰€æœ‰å‡ºç°çš„åˆ—åï¼Œä¿æŒé¡ºåº
    # å‡è®¾ 'ä½œä¸šæ¥æº' æ”¾åœ¨ç¬¬ä¸€åˆ—
    fieldnames = ['ä½œä¸šæ¥æº']
    seen_fields = set(fieldnames)
    
    for row in all_data:
        for key in row.keys():
            if key not in seen_fields:
                fieldnames.append(key)
                seen_fields.add(key)
                
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    
    try:
        with open(filename, mode='w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_data)
        print(f"æ˜ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {filename}")
        return filename
    except Exception as e:
        print(f"ä¿å­˜ CSV å¤±è´¥: {e}")
        return None

def run_monitor():
    # å…ˆæ¸…ç†è¿‡æœŸæŠ¥å‘Š
    clean_old_reports()

    checker = HiveChecker(HIVE_HOST, HIVE_PORT, HIVE_USER)
    results = []
    all_details = [] # ç”¨äºå­˜å‚¨æ‰€æœ‰è¡¨çš„æ˜ç»†æ•°æ®
    
    print("å¼€å§‹æ‰§è¡Œæ•°æ®è´¨é‡ç›‘æ§...")
    try:
        # è®¡ç®—è¿‡æ»¤æ—¥æœŸ (å½“å‰æ—¥æœŸ - 3å¤©)
        three_days_ago = get_date_str(3)
        print(f"æŸ¥è¯¢è¿‡æ»¤æ¡ä»¶: ds > {three_days_ago}")

        for table in TARGET_TABLES:
            # å»æ‰åº“åæ˜¾ç¤ºï¼Œä¿æŒç®€æ´
            short_table_name = table.split('.')[-1]
            
            print(f"æ­£åœ¨æ£€æŸ¥è¡¨: {short_table_name}")
            # ä¼ å…¥ min_ds å‚æ•°
            max_ds, count = checker.get_latest_partition_info(table, min_ds=three_days_ago)
            
            # è·å–åŸºç¡€æ£€æŸ¥é¡¹
            checks = check_table_status_detail(max_ds, count)
            
            # çŠ¶æ€åˆ†å¸ƒæ£€æŸ¥ (å¦‚æœåŸºç¡€æ£€æŸ¥é€šè¿‡ä¸”æœ‰æ•°æ®)
            # é»˜è®¤çŠ¶æ€æ£€æŸ¥é€šè¿‡
            status_check = {
                "name": "æ•°æ®çŠ¶æ€",
                "passed": True,
                "msg": "æ­£å¸¸"
            }
            
            # å¦‚æœå‰é¢æœ‰å¤±è´¥ï¼Œæˆ–è€…æ²¡æ•°æ®ï¼Œå¯èƒ½æ— æ³•æ£€æŸ¥çŠ¶æ€ï¼Œæˆ–è€…çŠ¶æ€æ£€æŸ¥ä¹Ÿè§†ä¸ºä¸é€šè¿‡(è§†æƒ…å†µè€Œå®š)
            # è¿™é‡Œé€»è¾‘ï¼šå¦‚æœæœ‰æ•°æ®ï¼Œå°±å»æŸ¥çŠ¶æ€ï¼›å¦‚æœæ²¡æœ‰æ•°æ®ï¼ŒçŠ¶æ€æ£€æŸ¥æ˜¾ç¤ºä¸º"æ— æ•°æ®è·³è¿‡"æˆ–è€…åŒ…å«åœ¨æ•°æ®é‡æ£€æŸ¥é‡Œ
            
            if count > 0:
                has_status, is_abnormal, dist_msg = checker.check_status_distribution(table, max_ds)
                if has_status:
                    if is_abnormal:
                        status_check["passed"] = False
                        status_check["msg"] = dist_msg # å¦‚ "status å­—æ®µå€¼å…¨éƒ¨ä¸º 1"
                    else:
                        status_check["msg"] = "æ­£å¸¸" # æ˜¾å¼è¦†ç›–
                else:
                     status_check["msg"] = "æ—  status å­—æ®µ" # å¯é€‰ï¼Œè§†éœ€æ±‚æ˜¯å¦ä½œä¸ºé€šè¿‡
            else:
                status_check["msg"] = "-"

            checks.append(status_check)
            
            # æ±‡æ€»è¯¥è¡¨æ˜¯å¦æ•´ä½“å¥åº·
            is_healthy = all(c['passed'] for c in checks)
            
            results.append({
                "table": short_table_name,
                "checks": checks,
                "is_healthy": is_healthy
            })
            
            # å¦‚æœæœ‰æ•°æ®ï¼ŒæŸ¥è¯¢æ˜ç»†å¹¶æ±‡æ€»
            if max_ds and count > 0:
                cols, data = checker.get_partition_data(table, max_ds)
                for row in data:
                    # å°† row (tuple) è½¬ä¸º dictï¼Œå¹¶æ·»åŠ æ¥æºè¡¨ä¿¡æ¯
                    row_dict = dict(zip(cols, row))
                    row_dict['ä½œä¸šæ¥æº'] = short_table_name
                    all_details.append(row_dict)
            
    except Exception as e:
        print(f"ç›‘æ§æ‰§è¡Œè¿‡ç¨‹å‡ºé”™: {e}")
    finally:
        checker.close()
        
    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    today_str = get_date_str()
    report_lines = [
        f"### ğŸ“Š æ•°æ®è´¨é‡ç›‘æ§æ—¥æŠ¥",
        f"> ğŸ“… ç›‘æ§æ—¥æœŸ: {today_str}",
        ""
    ]
    
    for item in results:
        table = item['table']
        is_healthy = item['is_healthy']
        checks = item['checks']
        
        if is_healthy:
            # æ­£å¸¸æ˜¾ç¤º
            # æ ¼å¼ï¼š> **è¡¨å**
            #       > - æ£€æŸ¥é¡¹1: ç»“æœ
            report_lines.append(f"> **{table}**")
            check_strs = []
            for c in checks:
                check_strs.append(f"{c['name']}: {c['msg']}")
            # ç”¨ | åˆ†éš”æ˜¾ç¤ºåœ¨åŒä¸€è¡Œï¼Œæˆ–è€…åˆ†è¡Œ
            # ç”¨æˆ·è¦æ±‚"ç½—åˆ—å‡ºæ¥"ï¼Œåˆ†è¡Œå¯èƒ½æ›´æ¸…æ™°ï¼Œä½†ä¼šå¤ªé•¿ã€‚å°è¯•ä¸€è¡Œæ˜¾ç¤ºã€‚
            report_lines.append(f"> <font color=\"info\">{' | '.join(check_strs)}</font>")
            report_lines.append("") # ç©ºè¡Œ
        else:
            # å¼‚å¸¸æ˜¾ç¤ºï¼šæ›´åŠ æ˜æ˜¾
            # ä½¿ç”¨ä¸€çº§æˆ–äºŒçº§æ ‡é¢˜å¼ºè°ƒï¼Œæˆ–è€…åŠ ç²—çº¢è‰²
            report_lines.append(f"### âŒ {table} (å¼‚å¸¸)")
            for c in checks:
                icon = "âœ…" if c['passed'] else "ğŸ”»"
                color = "info" if c['passed'] else "warning"
                report_lines.append(f"- {icon} {c['name']}: <font color=\"{color}\">{c['msg']}</font>")
            report_lines.append("") # ç©ºè¡Œ

    markdown_content = "\n".join(report_lines)
    
    # åˆå§‹åŒ–å‘é€å™¨
    sender = WeChatSender(WEBHOOK_URL)
    
    # 1. å‘é€ Markdown æ¶ˆæ¯
    print("æ­£åœ¨å‘é€ä¼ä¸šå¾®ä¿¡ Markdown é€šçŸ¥...")
    response_md = sender.send_markdown(markdown_content)
    print(f"Markdown å‘é€ç»“æœ: {response_md}")
    
    # 2. ç”Ÿæˆå¹¶å‘é€ CSV æ˜ç»†æ–‡ä»¶
    # ä¿å­˜åˆ° reports ç›®å½•
    report_dir = os.path.join(os.getcwd(), "reports")
    csv_filename = os.path.join(report_dir, f"detail_report_{today_str}.csv")
    
    if save_details_to_csv(all_details, csv_filename):
        print(f"æ­£åœ¨ä¸Šä¼ å¹¶å‘é€æ–‡ä»¶: {csv_filename}...")
        media_id = sender.upload_file(csv_filename)
        if media_id:
            response_file = sender.send_file(media_id)
            print(f"æ–‡ä»¶å‘é€ç»“æœ: {response_file}")
        else:
            print("æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œè·³è¿‡æ–‡ä»¶å‘é€")

if __name__ == "__main__":
    run_monitor()
